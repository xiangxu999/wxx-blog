---
title: 深入客户端
date: 2023-09-14 09:53:40
permalink: /pages/7ae072/
categories:
  - 知识库
  - Kafka
tags:
  - 
---
## 一、分区分配策略

kafka提供了消费者客户端参数`partition.assignment.strategy`来设置消费者与订阅主题之间得分区分配策略，默认情况下，参数的值`org.apache.kafka.clients.consumer.RangeAssignor`，就是采用的`RangeAssignor`分配策略，除此以外kafka还提供`RoundRobinAssignor`和`StickyAssignor`分配策略。

### 1、RangeAssignor分配策略

RangeAssignor分配策略的原理是消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，来保证分区均匀分配给所有的消费者。

![image-20230914102143839](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230914102143839.png)

这种分配方式明显的一个问题是随着消费者订阅的Topic的数量的增加，不均衡的问题会越来越严重

### 2、RoundRobinAssignor分配策略

`RoundRobinAssignor`分配策略的原理是将消费组内所有消费组以及消费者订阅的所有主题的分区按照字典序排列，然后通过轮询方式逐个将分区依次分配给每个消费者。

![image-20230914102942367](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230914102942367.png)

但是如果每个消费者订阅的主题不同，就可能造成分配不均的情况：假设有三个消费者分别为C0、C1、C2，有3个Topic T0、T1、T2，分别拥有1、2、3个分区，并且C0订阅T0，C1订阅T0和T1，C2订阅T0、T1、T2，那么RoundRobinAssignor的分配结果如下：

![image-20230914103029246](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230914103029246.png)

### 3、StickyAssignor分配策略

`StickyAssignor`分区分配算法，目的是在执行一次新的分配时，能在上一次分配的结果的基础上，尽量少的调整分区分配的变动，节省因分区分配变化带来的开销，它的主要目的是：

- 分区的分配尽量的均衡。
- 每一次重分配的结果尽量与上一次分配结果保持一致。

假设消费组有3个消费者（C0，C1和C2），都订阅了4个主题（T0、T1、T2、T3），并且每个主题有两个分区：

![image-20230914104432733](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230914104432733.png)

`RoundRobinAssignor`分配策略会按照消费者C0和C2进行重新轮询分配，但是`StickyAssignor`分配策略会尽可能让前后两次分配相同，进而减少系统资源的损耗和其他异常情况的发生。

## 二、_consumer_offsets

位移提交的内容最终会保存到Kafka的内部主题_consumer_offsets中，其中OffsetCommitRequest请求格式如下：

![image-20230915101549487](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230915101549487.png)

`retention_time`：表示当前提交的消费位移所能保留的时长，如果是定时任务消费消息之后保存了消费位移，但是下一次执行的时间间隔超过这个时间，就会导致原来的位移消息丢失。

和消费位移对应的消息只定义了key和value字段的具体内容，不依赖具体版本的消息格式：

![image-20230915102749054](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230915102749054.png)

- key
  - `version`：value的version对应
  - `group`：消费组，确定这条消息所要存储的分度
  - `topic`：主题名称
  - `partition`：分区编号
- value
  - `version`：key的version对应
  - `offset`：消费位移
  - `metadata`：元数据信息
  - `commit_timestamp`：位移提交时间
  - `expire_timestamp`：位移超时时间戳

## 三、事务

消息中间件的消息传输保障有三个层级：

- `at most once`：至多一次，消息可能丢失，但绝对不会重复传输
- `at leat once`：最少一次，消息绝不会丢失，但可能会重复传输
- `exactly once`：恰好一次，每条消息肯定会被传输一次且仅传输一次

kafka为了保证消息的EOS，引入了幂等和事务两个特性：

### 1、幂等

所谓幂等简单来说就是对接口的多次调用所产生的结果和调用一次是一致的，生产者在进行重试的时候有可能会重复写入消息，而kafka的幂等性功能就可以避免这样的情况。

每个新的生产者实例化的时候都会分配一个PID，这个PID对用户而言是完全透明的，对于每个PID消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增，生产者每发送一条消息，对应的<PID，分区>的序列号的数值会加1，具体判断逻辑如下（SN_new表示新的序列号，SN_old表示旧的序列号）：

- SN_new = SN_old + 1，正常接受
- SN_new < SN_old + 1，说明消息被重复写入
- SN_new < SN_old + 1，说明消息丢失

### 2、事务

幂等性并不能跨多个分区运作，事务可以弥补这个缺陷，事务可以保证对多个分区写入操作的原子性。

```java
properties.put("transactional.id", "transactional")
```

## **参考**

**[官方文档](https://kafka.apache.org/documentation/)**

**[图解Kafka之实战指南](https://juejin.cn/book/6844733793220165639?enter_from=search_result&utm_source=search)**

