## 一、磁盘配置

- `log.dirs`：这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。要知道这个参数是没有默认值的
- `log.dir`：注意这是 dir，结尾没有 s，说明它只能表示单个路径，它是补充上一个参数用的。

这两个参数只需要配置`log.dirs`，由于是多个路径，需要用逗号来分隔，如果可以的话最好保证这些目录挂载到不同的物理磁盘上：

- 提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。
- 能够实现故障转移

## 二、Zookeeper配置

Zookeeper是一个分布式协调框架，负责协调管理并保存 Kafka 集群的所有元数据信息，比如集群都有哪些 Broker 在运行、创建了哪些 Topic，每个 Topic 都有多少分区以及这些分区的 Leader 副本都在哪些机器上等信息。

Kafka 与 ZooKeeper 相关的最重要的参数当属zookeeper.connect。这也是一个 CSV 格式的参数，比如我可以指定它的值为zk1:2181,zk2:2181,zk3:2181。

如果有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的zookeeper.connect参数可以这样指定：zk1:2181,zk2:2181,zk3:2181/kafka1和zk1:2181,zk2:2181,zk3:2181/kafka2。

## 三、Broker配置

客户端程序或其他 Broker 如何与该 Broker 进行通信的设置。有以下三个参数：

- `listeners`：学名叫监听器，其实就是告诉外部连接者要通过什么协议访问指定主机名和端口开放的 Kafka 服务。
- `advertised.listeners`：和 listeners 相比多了个 advertised。Advertised 的含义表示宣称的、公布的，就是说这组监听器是 Broker 用于对外发布的。
- `host.name/port`：废弃

其中监听器的概念是若干个逗号分隔的三元组，每个三元组的格式为`<协议名称，主机名，端口号>`，一旦你自己定义了协议名称，你必须还要指定`listener.security.protocol.map`参数告诉这个协议底层使用了哪种安全协议，比如指定`listener.security.protocol.map=CONTROLLER:PLAINTEXT`表示CONTROLLER这个自定义协议底层使用明文不加密传输数据。

## 四、topic配置

- `auto.create.topics.enable`：是否允许自动创建 Topic。

- `unclean.leader.election.enable`：是否允许 Unclean Leader 选举。

- `auto.leader.rebalance.enable`：是否允许定期进行 Leader 选举。

针对第一个参数最好设置成false，避免生产环境出现各种奇怪的名字，生产环境的topic要通过审批的形式来进行创建。

第二个参数是针对Unclean leader副本而言，因为在同步过程中，有些副本的进度是远远落后leader副本的，这些副本如果成为leader副本，可能会导致数据丢失的问题，所以这个参数也最好设置成false。

第三个参数定期进行leader选举，它并非是选leader，而是一段时间之后去换leader，类似现在leader是A，过了一段时间之后，换成B来作为leader，这样操作的代价很高，所以因此也设置为false

以上是服务端topic配置相关，对于单个topic使用层面，保存消息参数配置如下：

- `retention.ms`：规定了该 Topic 消息被保存的时长。默认是 7 天，即该 Topic 只保存最近 7 天的消息。一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。

- `retention.bytes`：规定了要为该 Topic 预留多大的磁盘空间。和全局参数作用相似，这个值通常在多租户的 Kafka 集群中会有用武之地。当前默认值是 -1，表示可以无限使用磁盘空间。

处理消息角度需要进行如下配置：

`max.message.bytes`：它决定了 Kafka Broker 能够正常接收该 Topic 的最大消息大小。

**创建topic语句**

```sh
bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880
```

**修改topic语句**

```sh
bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760
```

## 五、数据存储

- `log.retention.{hours|minutes|ms}`：这是个“三兄弟”，都是控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低。

- `log.retention.bytes`：这是指定 Broker 为消息保存的总磁盘容量大小。

- `message.max.bytes`：控制 Broker 能够接收的最大消息大小。

针对第一个参数虽然 ms 设置有最高的优先级，但是通常情况下我们还是设置 hours 级别的多一些，比如log.retention.hours=168表示默认保存 7 天的数据。

其次是这个log.retention.bytes。这个值默认是 -1，表明你想在这台 Broker 上保存多少数据都可以，至少在容量方面 Broker 绝对为你开绿灯，不会做任何阻拦。

第三个参数默认1000012 太少了，还不到 1MB。实际场景中突破 1MB 的消息都是屡见不鲜的，因此在线上环境中设置一个比较大的值还是比较保险的做法。

## 六、JVM参数

- `Java版本`：>=8.0
- `堆大小`：6GB

对应kafka的配置如下：

- `KAFKA_HEAP_OPTS`：指定堆大小。

- `KAFKA_JVM_PERFORMANCE_OPTS`：指定 GC 参数。

```sh
$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g
$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
$> bin/kafka-server-start.sh config/server.properties
```

## 七、操作系统配置

如果我们创建一个分区数很大的主题，会出现`too many open files`这个错误，这是由于文件描述符限制而引起的错误，实际上，文件描述符系统资源并不像我们想象的那样昂贵，你不用太担心调大此值会有什么不利的影响。通常情况下将它设置成一个超大的值是合理的做法，比如ulimit -n 1000000。

## **参考**

**[官方文档](https://kafka.apache.org/documentation/)**

**[图解Kafka之实战指南](https://juejin.cn/book/6844733793220165639?enter_from=search_result&utm_source=search)**

