---
title: Kafka
date: 2023-04-07 10:38:37
permalink: /pages/b926d5/
categories:
  - 工具使用
tags:
  - 消息队列
---
## 一、Kafka安装

### 1、JDK安装和配置

参考[Linux配置Java环境变量](https://cloud.tencent.com/developer/article/2163752)

> 推荐在Linux上进行Kafka安装和启动

### 2、下载安装包

[官方安装地址](https://www.apache.org/dyn/closer.cgi?path=/kafka/3.4.0/kafka_2.13-3.4.0.tgz)

```shell
tar -xzf kafka_2.13-3.4.0.tgz 
cd kafka_2.13-3.4.0/
```

> Kafka控制脚本在Unix和Windows平台有所不同，在Windows平台，请使用 `bin\windows\` 而不是`bin/`, 并将脚本扩展名改为`.bat`

### 3、启动服务器

**ZooKeeper Service**

```shell
# linux
$ bin/zookeeper-server-start.sh config/zookeeper.properties
```

**Kafka Service**

```shell
# linux
$ bin/kafka-server-start.sh config/server.properties
```

如果需要在后台进行运行，需在上述命令末尾加上`&`

```shell
$ bin/zookeeper-server-start.sh config/zookeeper.properties &
$ bin/kafka-server-start.sh config/server.properties &
```

### 4、查看是否启动成功

```shell
[root@localhost kafka_2.13-3.4.0]# jps -l
65073 kafka.Kafka
64101 org.apache.zookeeper.server.quorum.QuorumPeerMain
65919 sun.tools.jps.Jps
```

### 5、创建topic

**创建**

```shell
$ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092
```

**查看描述**

```shell
$ bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092
```

```shell
# output
Topic: quickstart-events        TopicId: j7x6pJqJRaCuxb86QfccJg PartitionCount: 1       ReplicationFactor: 1    Configs: 
        Topic: quickstart-events        Partition: 0    Leader: 0       Replicas: 0     Isr: 0
```

### 6、发送消息

```shell
$ bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092
This is my first event
This is my second event
```

### 7、接收消息

```shell
$ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092
This is my first event
This is my second event
```

### 8、docker安装Kafka

**拉取镜像**

```
docker pull wurstmeister/zookeeper 
docker pull wurstmeister/kafka
```

**运行服务**

**zookeeper**

```
docker run -d --restart=always --log-driver json-file --log-opt max-size=100m --log-opt max-file=2  --name zookeeper -p 2181:2181 -v /etc/localtime:/etc/localtime wurstmeister/zookeeper
```

**kafka**

```
docker run -d  --log-driver json-file --log-opt max-size=100m --log-opt max-file=2 --name kafka -p 9092:9092 -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=本机地址:2181/kafka -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://本机地址:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -v /etc/localtime:/etc/localtime wurstmeister/kafka
```

**查看运行**

![image-20230407224553093](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230407224553093.png)

## 二、Kafka理论

### 1、基本作用

目前 Kafka 已经定位为一个分布式流式处理平台，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。

Kafka具备三个作用：

- **消息系统**：在异步处理、应用解耦、流量削锋和消息通讯四个场景得到应用。
- **存储系统**：Kafka 把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。
- **流式处理平台**：Kafka 不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库，比如窗口、连接、变换和聚合等各类操作。

### 2、基本概念

一个典型的 Kafka 体系架构包括若干 Producer、若干 Broker、若干 Consumer，以及一个 ZooKeeper 集群。

![image-20230407142506915](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230407142506915.png)

- **Producer：**生产者创建信息，为发送消息的一方。
- **Consumer：**消费者消费信息，为接受信息的一方。
- **Broker：** 服务代理节点服务代理节点。对于 Kafka 而言，Broker 可以简单地看作一个独立的 Kafka 服务节点或 Kafka 服务实例。

### 3、主题和分区

在 Kafka 中还有两个特别重要的概念—`主题（Topic）`与`分区（Partition）`。Kafka 中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题（发送到 Kafka 集群中的每一条消息都要指定一个主题），而消费者负责订阅主题并进行消费。

- **主题：**Kafka中的消息以主题为单位进行分类的，生产者负责将消息发送到特定的主题，消费者订阅主题来获取消息。

- **分区：**同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。

  > Kafka只能保证分区的有序，不能保证主题的有序。

![image-20230407163650931](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230407163650931.png)

Kafka 中的分区可以分布在不同的服务器（broker）上，也就是说，一个主题可以横跨多个 broker，以此来提供比单个 broker 更强大的性能。

### 4、多副本机制

同一分区的不同副本保持的是相同的信息，副本之间是`一主多从`的关系。

- leader副本负责处理读写请求。
- follower副本只负责于leader副本的消息同步。

副本处于不同的 broker 中，当 leader 副本出现故障时，从 follower 副本中重新选举新的 leader 副本对外提供服务。（类似Redis的哨兵机制）。

## 三、Kafka开发

### 1、基础案例

**安装依赖**

```xml
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>3.4.0</version>
</dependency>
```

**生产者**

```java
public class Producer {
    public static final String BROKER_LIST = "localhost:9092";
    public static final String TOPIC = "quickstart-events";

    public static void main(String[] args) {
        Properties properties = new Properties();
        properties.put("key.serializer",
                "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer",
                "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("bootstrap.servers", BROKER_LIST);


        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "hello, Kafka!");
        try {
            producer.send(record);
        } catch (Exception e) {
            e.printStackTrace();
        }
        producer.close();
    }
}
```

- 定义一个配置Properties
- 创建一个生产者，并配置
- 生产者往定义的topic发送信息

**消费者**

```java
public class Consumer {
    public static final String BROKER_LIST = "localhost:9092";
    public static final String TOPIC = "quickstart-events";
    public static final String GROUP_ID = "group.demo";

    public static void main(String[] args) {
        Properties properties = new Properties();
        properties.put("key.deserializer",
                "org.apache.kafka.common.serialization.StringDeserializer");
        properties.put("value.deserializer",
                "org.apache.kafka.common.serialization.StringDeserializer");
        properties.put("bootstrap.servers", BROKER_LIST);
        //设置消费组的名称，具体的释义可以参见第3章
        properties.put("group.id", GROUP_ID);
        //创建一个消费者客户端实例
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        //订阅主题
        consumer.subscribe(Collections.singleton(TOPIC));
        //循环消费消息
        while (true) {
            ConsumerRecords<String, String> records =
                    consumer.poll(Duration.ofMillis(10000));
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(record.value());
            }
        }
    }
}
```

- 定义一个配置Properties。
- 创建一个消费者，并配置。
- 消费者订阅topic。
- 消费者获取消息。

### 2、SpringBoot整合

待完善

## 四、生产者客户端开发

### 1、生产者逻辑

1. 配置生产者客户端参数及创建相应的生产者实例。
2. 构建待发送的消息。
3. 发送消息。
4. 关闭生产者实例。

### 2、配置优化

针对我们的Properties配置，我们可以采用配置文件的方式或者静态实例的方式来进行加载。

**静态实例**

```java
    public static Properties initConfig(){
        Properties props = new Properties();
        props.put("bootstrap.servers", brokerList);
        props.put("key.serializer",
                "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer",
                "org.apache.kafka.common.serialization.StringSerializer");
        props.put("client.id", "producer.client.id.demo");
        return props;
    }
```

**配置文件**

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      retries: 0
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
```

- `bootstrap.servers`：该参数用来指定生产者客户端连接 Kafka 集群所需的 broker 地址清单，具体的内容格式为 host1:port1,host2:port2，可以设置一个或多个地址，中间以逗号隔开，此参数的默认值为“”。
- `key.serializer`和`value.serializer`：这两个参数分别用来指定 key 和 value 序列化操作的序列化器。
- ` client.id`：这个参数用来设定 KafkaProducer 对应的客户端id，默认值为“”。

**配置key优化**

实际配置过程中，key由于字符串过长，容易出错。

我们可以直接使用客户端中的 org.apache.kafka.clients.producer.ProducerConfig 类来做一定程度上的预防措施。

```java
    public static Properties initConfig(){
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
                "org.apache.kafka.common.serialization.StringSerializer");
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                "org.apache.kafka.common.serialization.StringSerializer");
        props.put(ProducerConfig.CLIENT_ID_CONFIG, "producer.client.id.demo");
        return props;
    }
```

### 3、消息对象

在发送消息之前，我们要进行消息对象的构建：

```java
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "hello, Kafka!");
```

发送的消息对象包括记录要发送到的主题名称、可选的分区号以及可选的键和值。 

```java
public class ProducerRecord<K, V> {
    private final String topic; //主题
    private final Integer partition; //分区号
    private final Headers headers; //消息头部
    private final K key; //键
    private final V value; //值
    private final Long timestamp; //消息的时间戳
    //省略其他成员方法和构造方法
}
```

- 主题：消息的分类。
- 分区号
  - 如果指定了有效的分区号，则在发送记录时将使用该分区。
  - 如果没有指定分区，但有一个键，则会使用键的散列选择分区。
  - 如果键和分区都不存在，分区将以循环方式分配。
- Key：是用来指定消息的键，它不仅是消息的附加信息，还可以用来计算分区号进而可以让消息发往特定的分区。
- value：消息的内容。

### 4、消息发送

发送消息的方法，其中`topic`和`value`是必须的：

```java
    public ProducerRecord(String topic, Integer partition, Long timestamp, 
                          K key, V value, Iterable<Header> headers)
    public ProducerRecord(String topic, Integer partition, Long timestamp,
                          K key, V value)
    public ProducerRecord(String topic, Integer partition, K key, V value, 
                          Iterable<Header> headers)
    public ProducerRecord(String topic, Integer partition, K key, V value)
    public ProducerRecord(String topic, K key, V value)
    public ProducerRecord(String topic, V value)
```

创建生产者实例和构建消息之后，就可以开始发送消息了。发送消息主要有三种模式：

- 发后即忘（fire-and-forget）
- 同步（sync）
- 异步（async）

**发后即忘**

```java
    KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
    ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "hello, Kafka!");
    try {
        producer.send(record);
    } catch (Exception e) {
        e.printStackTrace();
    }
    producer.close();
```

这种就是典型的`发后即忘`模式，只管往 Kafka 中发送消息而并不关心消息是否正确到达，有如下特点：

- 性能高
- 可靠性差

**同步方式**

```java
    public Future<RecordMetadata> send(ProducerRecord<K, V> record)
```

```java
    try {
        producer.send(record).get();
    } catch (ExecutionException | InterruptedException e) {
        e.printStackTrace();
    }
```

实际上 send() 方法本身就是异步的，send() 方法返回的 Future 对象可以使调用方稍后获得发送的结果。示例中在执行 send() 方法之后直接链式调用了 get() 方法来阻塞等待 Kafka 的响应，直到消息发送成功，或者发生异常。如果发生异常，那么就需要捕获异常并交由外层逻辑处理。

如果要获取消息的一些元数据信息，可以采用如下方式：

```java
    try {
        Future<RecordMetadata> future = producer.send(record);
        RecordMetadata metadata = future.get();
        System.out.println(metadata.topic() + "-" +
                           metadata.partition() + ":" + metadata.offset());
    } catch (ExecutionException | InterruptedException e) {
        e.printStackTrace();
    }
```

同步的发送方式有如下特点：

- 同步发送的方式可靠性高，要么消息被发送成功，要么发生异常。如果发生异常，则可以捕获并进行相应的处理。
- 同步发送的方式性能会差很多，需要阻塞等待一条消息发送完之后才能发送下一条。

**异常处理**

KafkaProducer 中一般会发生两种类型的异常：

- 可重试的异常：
- 不可重试的异常：

对于可重试的异常，如果配置了 retries 参数，那么只要在规定的重试次数内自行恢复了，就不会抛出异常。retries 参数的默认值为0，配置方式参考如下：

```java
    props.put(ProducerConfig.RETRIES_CONFIG, 10);
```

**异步**

send() 方法的返回值类型就是 Future，而 Future 本身就可以用作异步的逻辑处理。

但是由于这个方法可以随时调用`get方法`，以及怎么调用都是需要面对的问题，消息不停地发送，那么诸多消息对应的 Future 对象的处理难免会引起代码处理逻辑的混乱。

因此采用Callback 的方式非常简洁明了，Kafka 有响应时就会回调，要么发送成功，要么抛出异常。

```java
    public static void main(String[] args) {
        Properties properties = initConfig();
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "hello, Kafka!");
        try {
            producer.send(record, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    System.out.println(metadata.topic() + "-" +
                            metadata.partition() + ":" + metadata.offset());
                }
            });
        } catch (Exception e) {
            e.printStackTrace();
        }
        producer.close();
    }
```

回调函数中有两个参数：

- RecordMetadata：消息元数据，可以获得主题、位移量等
- Exception：异常

**回调的先后顺序**

假设我们发送了两条消息，代码如下：

```java
    producer.send(record1, callback1);
    producer.send(record2, callback2);
```

对于同一个分区而言，如果消息 record1 于 record2 之前先发送，那么 KafkaProducer 就可以保证对应的 callback1 在 callback2 之前调用，也就是说，回调函数的调用也可以保证分区有序。

### 5、资源回收

在日常业务需求中，`KafkaProducer`可能会发送好几条消息，在发送完这些消息之后，需要调用 KafkaProducer 的 close() 方法来回收资源。

```java
	producer.close();
```

这个无参`close`方法，阻塞等待之前所有的发送请求完成后再关闭 KafkaProducer。

对应有一个带有参数的`close`方法：

```java
	public void close(long timeout, TimeUnit timeUnit)
```

如果调用了带超时时间 timeout 的 close() 方法，那么只会在等待 timeout 时间内来完成所有尚未完成的请求处理，然后强行退出。

> 在实际应用中，一般使用的都是无参的 close() 方法。

## 五、序列化-分区器-拦截器（生产者）

客户端消息在真正发送到`Broker`，还会经历三个过程：

- 序列化：需要把对象转化为二进制流的方式
- 分区器：如果没有指定分区，就需要根据 key 这个字段来计算 partition 的值。分区器的作用就是为消息分配分区。
- 拦截器：在消息发送之前进行一定处理

### 1、序列化

在之前的案例中，我们生产者序列化和消费者反序列化的方式如下：

```java
    public static Properties initConfig(){
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
                "org.apache.kafka.common.serialization.StringSerializer");
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                "org.apache.kafka.common.serialization.StringSerializer");
        props.put(ProducerConfig.CLIENT_ID_CONFIG, "producer.client.id.demo");
        return props;
    }
```

因为我们发送和接受都是`String`，所以我们采用的`StringSerializer`序列化。

Kafka有许多序列化器，但是他们都实现了`Serializer<T>`接口：

```java
public interface Serializer<T> extends Closeable {

    default void configure(Map<String, ?> configs, boolean isKey) {
        // intentionally left blank
    }

    byte[] serialize(String topic, T data);

    default byte[] serialize(String topic, Headers headers, T data) {
        return serialize(topic, data);
    }
    
    @Override
    default void close() {
        // intentionally left blank
    }
}
```

通常而言，还是采用Json进行序列化和反序列化操作。

### 2、分区器

消息经过序列化之后就需要确定它发往的分区，如果消息 ProducerRecord 中指定了 partition 字段，那么就不需要分区器的作用，因为 partition 代表的就是所要发往的分区号。

如果消息 ProducerRecord 中没有指定 partition 字段，那么就需要依赖分区器，根据 key 这个字段来计算 partition 的值。分区器的作用就是为消息分配分区。

Kafka的分区器都实现了`Partitioner`接口:

```java
    public int partition(String topic, Object key, byte[] keyBytes, 
                         Object value, byte[] valueBytes, Cluster cluster);
    public void close();
```

其中 partition() 方法用来计算分区号，返回值为 int 类型。

partition() 方法中的参数：

- topic：主题、
- Key：键
- keyBytes：序列化后的键
- value：值
- valueBytes：序列化后的值

- cluster：当前集群元数据

如果我们要根据业务去实现一个特殊的分区器，只需要实现这个接口，然后配置即可：

```java
public class DemoPartitioner implements Partitioner {
    private final AtomicInteger counter = new AtomicInteger(0);

    @Override
    public int partition(String topic, Object key, byte[] keyBytes,
                         Object value, byte[] valueBytes, Cluster cluster) {
       // todo
       return 0;
    }

    @Override public void close() {}

    @Override public void configure(Map<String, ?> configs) {}
}
```

```java
props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,
        DemoPartitioner.class.getName());
```

### 3、生产拦截器

生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。

生产者拦截器需要实现`ProducerInterceptor` 接口：

```java
    public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);
    public void onAcknowledgement(RecordMetadata metadata, Exception exception);
    public void close();
```

KafkaProducer 在将消息序列化和计算分区之前会调用生产者拦截器的 onSend() 方法来对消息进行相应的定制化操作。

KafkaProducer 会在消息被应答（Acknowledgement）之前或消息发送失败时调用生产者拦截器的 onAcknowledgement() 方法，优先于用户设定的 Callback 之前执行。

**案例实现**

我们有如下业务：需要在发送的信息之前添加`test`前缀，并记录发送成功多少条，发送失败多少条。

> 一般来说最好不要修改消息 ProducerRecord 的 topic、key 和 partition 等信息。

拦截器代码：

```java
public class TestInterceptorPrefix implements ProducerInterceptor {

    private volatile long sendSuccess = 0;
    private volatile long sendFailure = 0;

    @Override
    public ProducerRecord onSend(ProducerRecord record) {
        String modifiedValue = "test-" + record.value();
        return new ProducerRecord<>(record.topic(),
                record.partition(), record.timestamp(),
                record.key(), modifiedValue, record.headers());
    }

    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        if (exception == null) {
            sendSuccess++;
        } else {
            sendFailure ++;
        }
    }

    @Override
    public void close() {
        System.out.println("发送成功次数：" + sendSuccess);
        System.out.println("发送成功次数：" + sendFailure);
    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

配置

```java
        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,
                TestInterceptorPrefix.class.getName());
```

输出

```java
// 生产者
发送成功次数：10
发送成功次数：0

// 消费者
test-Kafka
test-Kafka
test-Kafka
test-Kafka
test-Kafka
test-Kafka
test-Kafka
test-Kafka
test-Kafka
test-Kafka
```

**拦截链**

KafkaProducer 中不仅可以指定一个拦截器，还可以指定多个拦截器以形成拦截链。拦截链会按照 interceptor.classes 参数配置的拦截器的顺序来。

> 配置的时候，各个拦截器之间使用逗号隔开。

现在我们额外配置一个拦截器：

```java
public class TestPlusInterceptorPrefix implements ProducerInterceptor {
    @Override
    public ProducerRecord onSend(ProducerRecord record) {
        String modifiedValue = "testPlus-"+record.value() ;
        return new ProducerRecord<>(record.topic(),
                record.partition(), record.timestamp(),
                record.key(), modifiedValue, record.headers());
    }

    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {

    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

拦截器链配置

```java
        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,
                TestInterceptorPrefix.class.getName() + "," + TestPlusInterceptorPrefix.class.getName());
```

消费者输出

```java
testPlus-test-Kafka
```

在拦截链中，如果某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。所以对于A和B拦截器，如果B拦截器依赖于A拦截器逻辑处理，这个时候如果A执行失败，那么B仍然会进行执行，相关逻辑就会出现问题。

## 六、生产者客户端发送原理

整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和 Sender 线程（发送线程）。

![image-20230410112732248](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230410112732248.png)

### 1、拦截器-序列化器-分区器

- 拦截器：发送消息之前进行额外的处理。
- 序列化器：将对象序列化为字节数组。
- 分区器：按照一定规则把消息送往对应分区。

### 2、RecordAccumulator

**主要作用**

主要用来缓存消息以便 Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能。

如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这个时候 KafkaProducer 的 send() 方法调用要么被阻塞，要么抛出异常，这个取决于参数 max.block.ms 的配置，此参数的默认值为60000，即60秒。

**内部原理**

RecordAccumulator内部为每个分区都维护了一个双端队列，队列中的内容就是 ProducerBatch，即 Deque。

消息写入的时候，追加到队列，消息读取从队头读取。

ProducerBatch 不是 ProducerRecord，ProducerBatch 中可以包含一至多个 ProducerRecord，通过这样减少网络请求的次数以提升整体的吞吐量

- ProducerRecord：发送的一个消息
- ProducerBatch：发送的一个消息批次，包含多个消息

### 3、Sender

**分区转broker**

对于客户端Producer：只关心发送到那个分区

对于网络连接：只关心发送到那个具体broker

所以，Sender 从 RecordAccumulator 中获取缓存的消息之后，会进一步将原本<分区, Deque< ProducerBatch>> 的保存形式转变成 <Node, List< ProducerBatch> 的形式。需要做一个应用逻辑层面到网络I/O层面的转换。

**封装Request**

在转换成 <Node, List> 的形式之后，Sender 还会进一步封装成 <Node, Request> 的形式，这样就可以将 Request 请求发往各个 Node 了，这里的 Request 是指 Kafka 的各种协议请求，对于消息发送而言就是指具体的 ProduceRequest。

## 七、消费者与消费组

### 1、基本概念

消费者（Consumer）负责订阅 Kafka 中的主题（Topic），并且从订阅的主题上拉取消息。

与其他一些消息中间件不同的是：在 Kafka 的消费理念中还有一层消费组（Consumer Group）的概念，每个消费者都有一个对应的消费组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。

![image-20230410142505336](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230410142505336.png)



在上图中，存在`消费者组A`和`消费者组B`，对应关系如下：

- 消费组A
  - P0 - C0
  - P1 - C1
  - P2 - C2
  - P3 - C3
- 消费组B
  - P0和P1 - C4
  - P2和P3 - C5

两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。

### 2、消费组的伸缩

**一个消费者**

![image-20230410143236913](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230410143236913.png)

现在一个消费组里面只有一个消费者，那么这个消费者C0订阅了7个分区。

**两个消费者**

![image-20230410143322200](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230410143322200.png)

现在一个消费组里面有两个消费者，按照既定的逻辑，需要将原来消费者C0的部分分区分配给消费者C1消费，如上图所示。消费者C0和C1各自负责消费所分配到的分区，彼此之间并无逻辑上的干扰。

**多个消费者**

消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性，我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力。

但是如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区。

![image-20230410143648986](https://blog-1300853183.cos.ap-chengdu.myqcloud.com/img/image-20230410143648986.png)

### 3、消息投递模式

点对点：基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。

发布/订阅：定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题（Topic），主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。

- 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。
- 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。

## 八、消费者客户端开发

### 1、消费者逻辑

- 配置消费者客户端参数及创建相应的消费者实例。

- 订阅主题。

- 拉取消息并消费。

- 提交消费位移。

- 关闭消费者实例。

### 2、配置优化

**静态实例**

```java
    public static Properties initConfig(){
        Properties props = new Properties();
        props.put("key.deserializer",
                "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer",
                "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("bootstrap.servers",  BROKER_LIST);
        props.put("group.id", GROUP_ID);
        props.put("client.id", "consumer.client.id.demo");
        return props;
    }
```

**配置文件**

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: spring-boot-demo
      # 手动提交
      enable-auto-commit: false
      auto-offset-reset: latest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        session.timeout.ms: 60000
```

- `bootstrap.servers`：该参数用来指定生产者客户端连接 Kafka 集群所需的 broker 地址清单，具体的内容格式为 host1:port1,host2:port2，可以设置一个或多个地址，中间以逗号隔开，此参数的默认值为“”。
- `key.serializer`和`value.serializer`：这两个参数分别用来指定 key 和 value 反序列化操作的序列化器。
- ` client.id`：KafkaConsumer 对应的客户端id，默认值也为“”。
- `group.id`：消费者隶属的消费组的名称，默认值为“”。

> 这部分同样可以采用相关静态常量避免出错。

### 3、订阅主题和分区

**主题订阅**

在创建好消费者之后，我们就需要为该消费者订阅相关的主题了。一个消费者可以订阅一个或多个主题。

```java
        //创建一个消费者客户端实例
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        //订阅主题
        consumer.subscribe(Collections.singletonList(TOPIC));
```

如果前后两次订阅了不同的主题，那么消费者以最后一次的为准：

```java
consumer.subscribe(Arrays.asList(topic1));
consumer.subscribe(Arrays.asList(topic2));
```

上述代码中，消费者最终订阅的是topic2

**分区订阅**

消费者不仅可以通过 KafkaConsumer.subscribe() 方法订阅主题，还可以直接订阅某些主题的特定分区，在 KafkaConsumer 中还提供了一个 assign() 方法来实现这些功能，此方法的具体定义如下：

```java
public void assign(Collection<TopicPartition> partitions)
```

TopicPartition类如下：

```java
public final class TopicPartition implements Serializable {

    private final int partition;
    private final String topic;

    public TopicPartition(String topic, int partition) {
        this.partition = partition;
        this.topic = topic;
    }

    public int partition() {
        return partition;
    }

    public String topic() {
        return topic;
    }
    //省略hashCode()、equals()和toString()方法
}
```

- topic：主题名
- partition：分区号

如果我们要订阅`quickstart-events`主题，分区为0：

```java
consumer.assign(Arrays.asList(new TopicPartition("quickstart-events", 0)));
```

**分区信息获取**

KafkaConsumer 中的 partitionsFor() 方法可以用来查询指定主题的元数据信息，partitionsFor() 方法的具体定义如下：

```java
public List<PartitionInfo> partitionsFor(String topic)
```

```java
public class PartitionInfo {
    private final String topic;
    private final int partition;
    private final Node leader;
    private final Node[] replicas;
    private final Node[] inSyncReplicas;
    private final Node[] offlineReplicas;
}
```

演示通过主题订阅主题下的全部分区

```java
    List<TopicPartition> partitions = new ArrayList<>();
    List<PartitionInfo> partitionInfos = consumer.partitionsFor(TOPIC);
    if (partitionInfos != null) {
        for (PartitionInfo tpInfo : partitionInfos) {
            partitions.add(new TopicPartition(tpInfo.topic(), tpInfo.partition()));
        }
    }
    consumer.assign(partitions);
```

- 通过主题获取元数据信息
- 遍历元数据信息，放入到分区集合中
- 订阅分区集合

**取消订阅**

```java
consumer.unsubscribe();
```

## 参考

[官方文档](https://kafka.apache.org/documentation/)

[图解Kafka之实战指南](https://juejin.cn/book/6844733793220165639?enter_from=search_result&utm_source=search)